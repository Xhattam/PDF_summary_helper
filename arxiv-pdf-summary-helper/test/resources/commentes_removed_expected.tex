\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{bm}
\usepackage{array}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{url}
\usepackage{color}

\usepackage{verbatim}


\newcommand\BibTeX{B{\sc ib}\TeX}

\title{CAN: Constrained Attention Networks for Multi-Aspect Sentiment Analysis}
\author{Mengting Hu\textsuperscript{1}\thanks{\quad This work was done when Mengting Hu was a research intern at IBM Research - China.}, Shiwan Zhao\textsuperscript{2}, Li Zhang\textsuperscript{2}, Keke Cai\textsuperscript{2},
Zhong Su\textsuperscript{2}, Renhong Cheng\textsuperscript{1}, Xiaowei Shen\textsuperscript{2} \\
\textsuperscript{1} Nankai University, \textsuperscript{2} IBM Research - China \\
mthu@mail.nankai.edu.cn, \{zhaosw, lizhang, caikeke, suzhong\}@cn.ibm.com, \\ chengrh@nankai.edu.cn, xwshen@cn.ibm.com
}

\begin{document}
\maketitle
\begin{abstract}
Aspect level sentiment classification is a fine-grained sentiment analysis task, compared to the sentence level classification. A sentence usually contains one or more aspects. To detect the sentiment towards a particular aspect in a sentence, previous studies have developed various methods for generating aspect-specific sentence representations. However, these studies handle each aspect of a sentence separately. In this paper, we argue that multiple aspects of a sentence are usually orthogonal based on the observation that different aspects concentrate on different parts of the sentence. To force the orthogonality among aspects, we propose constrained attention networks (CAN) for multi-aspect sentiment analysis, which handles multiple aspects of a sentence simultaneously. Experimental results on two public datasets demonstrate the effectiveness of our approach. We also extend our approach to multi-task settings, outperforming the state-of-the-arts significantly.
\end{abstract}
\section{Introduction}
Sentiment analysis \cite{Nasukawa2003Sentiment,liu2012sentiment}, an important task in natural language understanding, receives much attention in recent years. Aspect level sentiment classification is a fine-grained sentiment analysis task, which aims at detecting the sentiment towards a particular aspect in a sentence. A multi-aspect sentence (\emph{i.e.}, the sentence contains more than one aspect) can be categorized as {\bf overlapping} or {\bf non-overlapping}. A sentence is annotated as non-overlapping only if any two of its aspects have no overlap. One key observation is that around $85\%$ of the multi-aspect sentences are non-overlapping in the two public datasets. Figure \ref{sentence} shows a simple example. The non-overlapping sentence contains two aspects. The aspect \emph{food} is in the left part of the sentence while \emph{service} in the right part. Their distributions on words are {\bf orthogonal} to each other. Another observation is that only a few words relate to the opinion expression in each aspect. As shown in Figure \ref{sentence}, only the word \emph{``great''} is relevant to the aspect \emph{food} and \emph{``dreadful"} to \emph{service}. The distribution of the opinion expression of each aspect is {\bf sparse}.

To detect the sentiment towards a particular aspect, previous studies \cite{Wang2016Attention,Ma2017Interactive,cheng2017aspect,ma2018targeted,huang2018aspect,wang2018learning} have developed various attention-based methods for generating aspect-specific sentence representations. To name a few, \cite{Wang2016Attention} proposes attention-based LSTMs for aspect level sentiment classification. The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input.
\cite{wang2018learning} proposes a segmentation attention based LSTM model which can effectively capture the structural dependencies between the target and the sentiment expressions with a linear-chain conditional random field (CRF) layer. However, all these works are single-aspect sentiment analysis, which deals with aspects in a sentence one at a time, ignoring the orthogonality among multiple aspects.

\begin{figure}
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{-0.2cm}
\centering
\includegraphics[width=0.45\textwidth]{example.pdf}
\caption{Example of a non-overlapping sentence.}
  \label{sentence}
\end{figure}

Therefore, we propose a model for multi-aspect sentiment analysis, which handles multiple aspects of a sentence simultaneously. Specifically, we introduce orthogonal regularization for attention weights among multiple non-overlapping aspects. The orthogonal regularization tends to make the attention weights of multiple aspects concentrate on different parts of the sentence with less overlap. We also introduce the sparse regularization, which tends to make the attention weights of each aspect concentrate only on a few words. We call our networks with such regularizations {\bf constrained attention networks} (CAN). The implementation of adding regularization terms to attention weights of multiple aspects is similar to adding the penalization term in self-attention in \cite{lin2017structured}. The details will be introduced in the model section.

In addition to aspect level sentiment classification ({\bf ALSC}), aspect category detection ({\bf ACD}) is another task of aspect based sentiment analysis. We introduce ACD as an auxiliary task to assist the ALSC task, benefiting from the shared context of the two tasks. Aspect category detection~\cite{Zhou2015Representation,Schouten2018Supervised} is a task which aims to identify the aspect categories discussed in a given sentence from a predefined set of aspect categories (e.g., price, food, service). Take Figure \ref{sentence} as an example, aspect categories \emph{food} and \emph{service} are mentioned. We also apply our attention constraints to the ACD task. By applying attention weight constraints to both ALSC and ACD tasks in an end-to-end network, we further evaluate the effectiveness of CAN in multi-task settings.

In summary, the main contributions of our work are as follows:
\begin{itemize}
\vspace{-0.2cm}
\item We propose CAN for multi-aspect sentiment analysis. Specifically, we introduce {\bf orthogonal} and {\bf sparse} regularizations to constrain the attention weight allocation, helping learn better aspect-specific sentence representations. To the best of our knowledge, this is the first work for multi-aspect sentiment analysis.


\vspace{-0.2cm}
\item We extend CAN to multi-task settings by introducing ACD as an auxiliary task, and applying CAN on  both ALSC and ACD tasks.

\vspace{-0.2cm}
\item Extensive experiments are conducted on public datasets. Results demonstrate the effectiveness of our approach for aspect level sentiment classification.
\end{itemize}

\section{Related Work}
{\bf Aspect level sentiment classification} is a fine-grained sentiment analysis task. Earlier methods are usually based on explicit features \cite{liu2010improving,Vo2015Target}. \cite{liu2010improving} uses different linguistic features for sentiment classification. \cite{Vo2015Target} studies aspect-based Twitter sentiment classification by applying automatic features, which are obtained from unsupervised learning methods. With the rapid development of deep learning technologies, many end-to-end neural networks are implemented to solve this fine-grained task. \cite{Wang2016Attention} proposes an attention-based LSTM network for aspect-level sentiment
classification. \cite{Tay2017Learning} introduces a word aspect fusion attention layer to learn attentive representations. \cite{Ma2017Interactive} proposes the interactive attention
networks to generate the representations for targets and contexts separately. \cite{tay2017dyadic} proposes dyadic memory networks for aspect based sentiment analysis. \cite{cheng2017aspect,ruder2016hierarchical} both propose hierarchical neural network models for aspect level sentiment classification. \cite{ma2018targeted} proposes a two-step attention model for targeted aspect-based sentiment analysis. \cite{wang2018learning} proposes a segmentation
attention based LSTM model for aspect level sentiment classification. However, all these works can be categorized as single-aspect sentiment analysis, which deals with aspects in a sentence separately, ignoring the orthogonality among multiple aspects.

{\bf Multi-task learning} \cite{Caruana1997Multitask} solves multiple learning tasks at the same time, achieving improved performance by exploiting commonalities and differences across tasks. Multi-task learning has been used successfully in many  machine learning applications. \cite{Huang2018Multitask} learns both main task and auxiliary task jointly with shared representations, achieving improved performance in question answering. \cite{Toshniwal2017Multitask} uses low-level auxiliary tasks
for encoder-decoder based speech recognition, which suggests that the addition of auxiliary tasks can help in either optimization or generalization. \cite{yu2016learning} uses two auxiliary tasks to help induce a sentence embedding that works well across domains for sentiment classification. In this paper, we adopt the multi-task learning approach by using ACD as the auxiliary task to help the ALSC task.


\begin{figure*}
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{-0.3cm}
\centering
	\includegraphics[width=1.0\textwidth]{Big_network_new.pdf}
    \caption{Network Architecture. The aspect categories are embedded as vectors. The model encodes the sentence using LSTM. Based on its hidden states, aspect-specific sentence representations for ALSC and ACD tasks are learned via constrained attention. Then aspect level sentiment prediction and aspect category detection are made. }
    \label{network}
\end{figure*}
\section{Model}
We first formulate the problem. There are totally $N$ predefined aspect categories in the dataset, $A=\{A_1,...,A_N\}$. Given a sentence $S=\{w_1, w_2, ..., w_L\}$, which contains $K$ aspects $A^s=\{A_1^s,...,A_K^s\}, A^s\subseteq  A$, the multi-task learning is to simultaneously solve the ALSC and ACD tasks, namely, the ALSC task predicts the sentiment polarity of each aspect $A_k^s \in A^s$, and the auxiliary ACD task checks each aspect $A_n \in A$ to see whether the sentence $S$ mentions it.

We propose CAN for multi-aspect sentiment analysis, supporting both ALSC and ACD tasks by a multi-task learning framework. The network architecture is shown in Figure \ref{network}. We will introduce all components sequentially from left to right.

\subsection{Input and Embedding Layers}