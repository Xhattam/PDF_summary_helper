\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{bm}
\usepackage{array}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{url}
\usepackage{color}

\usepackage{verbatim}


\newcommand\BibTeX{B{\sc ib}\TeX}

\title{CAN: Constrained Attention Networks for Multi-Aspect Sentiment Analysis}
% \author{
%   Mengting Hu \\
%   {\tt mthu@mail.nankai.edu.cn} \\
%   {Nankai University, Tianjin, China} \\
%   \And
%   Shiwan Zhao \\
%   {\tt zhaosw@cn.ibm.com }      \\
%   {IBM Research - China, Beijing , China}
%   }
\author{Mengting Hu\textsuperscript{1}\thanks{\quad This work was done when Mengting Hu was a research intern at IBM Research - China.}, Shiwan Zhao\textsuperscript{2}, Li Zhang\textsuperscript{2}, Keke Cai\textsuperscript{2},
Zhong Su\textsuperscript{2}, Renhong Cheng\textsuperscript{1}, Xiaowei Shen\textsuperscript{2} \\
\textsuperscript{1} Nankai University, \textsuperscript{2} IBM Research - China \\
mthu@mail.nankai.edu.cn, \{zhaosw, lizhang, caikeke, suzhong\}@cn.ibm.com, \\ chengrh@nankai.edu.cn, xwshen@cn.ibm.com
}

\begin{document}
\maketitle
\begin{abstract}
Aspect level sentiment classification is a fine-grained sentiment analysis task, compared to the sentence level classification. A sentence usually contains one or more aspects. To detect the sentiment towards a particular aspect in a sentence, previous studies have developed various methods for generating aspect-specific sentence representations. However, these studies handle each aspect of a sentence separately. In this paper, we argue that multiple aspects of a sentence are usually orthogonal based on the observation that different aspects concentrate on different parts of the sentence. To force the orthogonality among aspects, we propose constrained attention networks (CAN) for multi-aspect sentiment analysis, which handles multiple aspects of a sentence simultaneously. Experimental results on two public datasets demonstrate the effectiveness of our approach. We also extend our approach to multi-task settings, outperforming the state-of-the-arts significantly.
\end{abstract}


\begin{figure}
\setlength{\abovecaptionskip}{0.2cm}    %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.2cm}   %调整图片标题与下文距离
\centering
\includegraphics[width=0.45\textwidth]{example.pdf}
\caption{Example of a non-overlapping sentence.} 
  \label{sentence} 
\end{figure}

\begin{itemize}
\vspace{-0.2cm}
\item We propose CAN for multi-aspect sentiment analysis. Specifically, we introduce {\bf orthogonal} and {\bf sparse} regularizations to constrain the attention weight allocation, helping learn better aspect-specific sentence representations. To the best of our knowledge, this is the first work for multi-aspect sentiment analysis.

%\vspace{-0.2cm}
%\item \textcolor{red}{For accurately constraining the sentences, we annotate two public datasets about whether multiple aspects in the sentence are overlap, and we will publish the datasets.} 

\vspace{-0.2cm}
\item We extend CAN to multi-task settings by introducing ACD as an auxiliary task, and applying CAN on  both ALSC and ACD tasks. 

\vspace{-0.2cm}
\item Extensive experiments are conducted on public datasets. Results demonstrate the effectiveness of our approach for aspect level sentiment classification.  
\end{itemize}

\subsection{Aspect Level Sentiment Classification}

\begin{figure*}
\setlength{\abovecaptionskip}{0.2cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.3cm}   %调整图片标题与下文距离
\centering
	\includegraphics[width=1.0\textwidth]{Big_network_new.pdf}
    \caption{Network Architecture. The aspect categories are embedded as vectors. The model encodes the sentence using LSTM. Based on its hidden states, aspect-specific sentence representations for ALSC and ACD tasks are learned via constrained attention. Then aspect level sentiment prediction and aspect category detection are made. }
    \label{network}
\end{figure*}

\subsection{Input and Embedding Layers}

\begin{equation} 
\setlength{\abovedisplayskip}{4pt}  % 公式与上文间距
\setlength{\belowdisplayskip}{4pt}  % 公式与下文间距
   h_l = LSTM(h_{l-1},v_l)
\end{equation}
%where $v_l$ is the input vector at time step $l$ and $h_{l-1}$ is the hidden state of the LSTM in previous time step $l-1$. 
The size of the hidden state is also set to be $d$.

\subsection{Task-Specific Attention Layer}
Our multi-task learning framework supports both ALSC and ACD tasks. The two tasks share the hidden states from the LSTM layer, while compute their own attention weights separately. The attention weights are then used to compute aspect-specific sentence representations. 

{\bf ALSC Attention Layer}
The key idea of aspect level sentiment classification is to learn different attention weights for different aspects, so that different aspects can concentrate on different parts of the sentence. 
%Multi-aspect sentiment analysis simultaneously handles multiple aspects by adding constraints to their attention weights. 
We follow the approach in \cite{Bahdanau2015iclr} to compute the attention. Particularly, given the sentence $S$ with $K$ aspects, $A^s=\{A_1^s,...,A_K^s\}$, for each aspect $A_k^s$, its attention weights are calculated by:
\begin{equation} 
\setlength{\abovedisplayskip}{4pt}  % 公式与上文间距
\setlength{\belowdisplayskip}{4pt}  % 公式与下文间距
    \alpha_k = softmax({z^a}^\mathrm{T}tanh(W_{1}^{a}{H} + W_{2}^{a}(u_k^{s}\otimes{e_L}))) 
  \label{equation_absa_att}
\end{equation}
where $u_k^{s}$ is the embedding of the aspect $A_k^s$, $e_L\in\mathbb{R}^{L}$ is a
vector of $1$s, ${u_k^{s}}\otimes{e_L}$ is the operation repeatedly concatenating $u_k^{s}$ for $L$ times. $W_{1}^a\in\mathbb{R}^{{d}\times{d}}$, $W_{2}^a\in\mathbb{R}^{{d}\times{d}}$ and $z^a\in\mathbb{R}^{d}$ are the weight matrices.

{\bf ACD Attention Layer} We treat the ACD task as multi-label classification problem for the set of $N$ aspect categories. For each aspect $A_n\in A$, its attention weights are calculated by:
\begin{equation} 
\setlength{\abovedisplayskip}{4pt}  % 公式与上文间距
\setlength{\belowdisplayskip}{4pt}  % 公式与下文间距
    \beta_n = softmax({z^b}^\mathrm{T}tanh(W_{1}^{b}{H} + W_{2}^{b}(u_n\otimes{e_L}))) 
  \label{equation_acd_att}
\end{equation}
where $u_n$ is the embedding of the aspect $A_n$. $W_{1}^b\in\mathbb{R}^{{d}\times{d}}$, $W_{2}^b\in\mathbb{R}^{{d}\times{d}}$ and $z^b\in\mathbb{R}^{d}$ are the weight matrices.

The ALSC and ACD tasks use the same attention mechanism, but they do not share parameters. The reason to use separated parameters is that, for the same aspect, the attention of ALSC concentrates more on opinion words, while ACD focuses more on aspect target terms (see the attention visualizations in Section~\ref{sec:att_vis}). 
%Take Figure \ref{sentence} as an example, for the aspect \emph{food}, ALSC concentrates more on the word \emph{``great''}, while ACD puts more attention on the word \emph{``taste''}.

\subsection{Regularization Layer}
Multi-aspect sentiment analysis simultaneously handles multiple aspects by adding constraints to their attention weights. {\bf Note that this layer is only available in the training stage}, in which the ground-truth aspects are known for calculating the regularization loss, and then influence parameter updating in back propagation. While in the testing/inference stage, the true aspects are unknown and the regularization loss is not calculated so that this layer is omitted from the architecture.  

In this paper, we introduce two types of regularizations: the sparse regularization on each single aspect; the orthogonal regularization on multiple non-overlapping aspects. 

{\bf Sparse Regularization} For each aspect, the sparse regularization constrains the distribution of the attention weights ($\alpha_k$ or $\beta_n$) to concentrate on less words. For simplicity, we use $\alpha_k$ as an example, $\alpha_k=\{\alpha_{k1},  \alpha_{k2}, ..., \alpha_{kL}\}$. To make $\alpha_k$ sparse, the sparse regularization term is defined as: 
\begin{equation} 
\setlength{\abovedisplayskip}{4pt}  % 公式与上文间距
\setlength{\belowdisplayskip}{4pt}  % 公式与下文间距
    R_s = \mid\sum\limits_{l=1}^L{\alpha_{kl}^{2}} - 1\mid
    \label{equation:sparse_reg}
\end{equation}

where $\sum\limits_{l=1}^L{\alpha_{kl}}=1$ and $\alpha_{kl}>0$. Since $\alpha_k$ is normalized as a probability distribution, $L_1$ norm is always equal to $1$ (the sum of the probabilities) and does not work as sparse regularization as usual. Minimizing Equation \ref{equation:sparse_reg} will force the sparsity of $\alpha_k$. It has the similar effect as minimizing the entropy of $\alpha_k$, which leads to placing more probabilities on less words.

{\bf Orthogonal Regularization} This regularization term forces orthogonality between attention weight vectors of different aspects, so that different aspects attend on different parts of the sentence with less overlap. Note that we only apply this regularization to non-overlapping multi-aspect sentences. Assume that the sentence $S$ contains $K$ non-overlapping aspects $\{A_1^s,...,A_K^s\}$ and their attention weight vectors are $\{\alpha_1,...,\alpha_K\}$. We pack them together as a two-dimensional attention matrix $M\in\mathbb{R}^{{K}\times{L}}$ to calculate the orthogonal regularization term.
\begin{equation}
\setlength{\abovedisplayskip}{4pt}  % 公式与上文间距
\setlength{\belowdisplayskip}{4pt}  % 公式与下文间距
	R_o = \parallel{M^{\mathrm{T}}}M - I\parallel_2
\end{equation}

\subsection{Datasets}

\begin{table}[t!]
\begin{center}
\setlength{\tabcolsep}{0.3mm}{
\begin{tabular} {|c|ccc|ccc|}
\hline
	\multirow{2}{*}{Dataset} &  \multicolumn{3}{c|}{\#sentences} & \multicolumn{3}{c|}{\#aspects}  \\
    \cline{2-7}
    & \emph{Single} &  \emph{Multi} &  Total &  \emph{Single} & \emph{Multi} & Total \\
	\hline
		Rest14\_Train & 2053 & 482 & 2535 & 2053 & 1047 & 3100\\
        Rest14\_Val & 412 & 94 & 506 & 412 & 201 & 613 \\
		Rest14\_Test & 611 & 189 & 800 & 611 & 414 & 1025 \\
        \hline
        Rest15\_Train & 622 & 309 & 931 & 622 & 766 & 1388 \\
        Rest15\_Val & 137 & 52 & 189 & 137 & 129 & 266 \\
        Rest15\_Test & 390 & 192 & 582 & 390 & 455 & 845 \\
	\hline
\end{tabular}}
\end{center}
\caption{\label{table-dataset} The numbers of single-aspect and multi-aspect sentences, and the numbers of aspects in single-aspect and multi-aspect sentences.}	
\end{table}
\end{comment}

\begin{table}[t!]
\setlength{\abovecaptionskip}{0.1cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.4cm}   %调整图片标题与下文距离
\begin{center}
\setlength{\tabcolsep}{1mm}{
\begin{tabular} {|c|c|ccc|c|}
\hline
    \multirow{2}{*}{Dataset} & \multirow{2}{*}{\#Single} & \multicolumn{3}{c|}{\#Multi} & \multirow{2}{*}{\#Total} \\
    \cline{3-5}
      &&  \emph{OL} & \emph{NOL} & \emph{Total} & \\
	\hline
		Rest14\_Train & 2053 & 67 & 415 & 482 & 2535\\
        Rest14\_Val & 412 & 19 & 75 & 94 & 506 \\
		Rest14\_Test & 611 & 27 & 162 & 189 & 800 \\
        \hline
        Rest15\_Train & 622 & 47 & 262 & 309 & 931 \\
        Rest15\_Val & 137 & 13 & 39 & 52 & 189 \\
        Rest15\_Test & 390 & 30 & 162 & 192 & 582 \\
	\hline
\end{tabular}}
\end{center}
\caption{\label{table-dataset} The numbers of single- and multi-aspect sentences. \emph{OL} and \emph{NOL} denote the overlapping and non-overlapping multi-aspect sentences, respectively.}	
\end{table}


\subsection{Comparison Methods}
\begin{itemize}
\item {\bf LSTM}: We implement the vanilla LSTM networks to model the sentence and use the average of all hidden states as the sentence representation. In this model, aspect information is not used.

\vspace{-6pt}
\item {\bf AT-LSTM} \cite{Wang2016Attention}: It adopts the attention mechanism in LSTM to generate a weighted representation of a sentence. The aspect embedding is used to compute the attention weights as in Equation \ref{equation_absa_att}. We do not concatenate the aspect embedding to the hidden state as in \cite{Wang2016Attention} and gain small performance improvement. We use this modified version of AT-LSTM in all experiments. 

\vspace{-6pt}
\item {\bf ATAE-LSTM} \cite{Wang2016Attention}: This method is an extension of AT-LSTM. In this model, the aspect embedding is concatenated to each word embedding of the sentence as the input to the LSTM layer. 

%\vspace{-5pt}
%\item {\bf AF-LSTM(CONV)} \cite{Tay2017Learning}: It utilizes circular convolution to compute deeper fusion relationships between each word in sentence and aspect.
\end{itemize}



\begin{table}[t!]
\setlength{\abovecaptionskip}{0.0cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.2cm}   %调整图片标题与下文距离
\begin{center}
\setlength{\tabcolsep}{1.5mm}{
\begin{tabular} {|c|cc|cc|}
\hline
	\multirow{2}{*}{Model} & \multicolumn{2}{c|}{Rest14} & \multicolumn{2}{c|}{Rest15} \\ 
    \cline{2-5}
    & 3-way & Binary & 3-way & Binary \\    
	\hline
    LSTM      & 80.61 & 86.66 & 73.14 & 73.27 \\ 
    AT-LSTM   & 81.66 & 87.13 & 75.15 & 76.40 \\
    ATAE-LSTM & 82.08 & 87.72 & 74.32 & 76.79 \\
    %AF-LSTM(CONV) & 81.29 & 87.26 & - & - \\
    \hline
    AT-CAN-$R_s$ & 81.97 & 88.08 & 75.74 & 80.05 \\
    AT-CAN-$R_o$ & 82.60 & 88.67 & 75.03 & 81.10 \\
    ATAE-CAN-$R_s$ & 82.29 & 87.37 &  76.09 & 80.83 \\
    ATAE-CAN-$R_o$ & {\bf 82.91} & {\bf 89.02} & {\bf 77.28} & {\bf 82.66} \\
	\hline
\end{tabular}}
\end{center}
\caption{\label{table-st} Results of the ALSC task in terms of accuracy ($\%$). All methods are run in single-task settings.}	
\end{table}

\begin{figure}
\setlength{\abovecaptionskip}{0.1cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.2cm}   %调整图片标题与下文距离
\centering
\subfigure[AT-LSTM]{
\includegraphics[width=0.45\textwidth]{at_.pdf}}
\vspace{-5pt}
\subfigure[M-AT-LSTM]{
\includegraphics[width=0.45\textwidth]{at_r2_.pdf}}
\vspace{-5pt}
\subfigure[M-CAN-2$R_o$]{
\includegraphics[width=0.45\textwidth]{multitask_at_2r2_.pdf}}
\caption{Visualization of attention weights of different aspects in the ALSC task. Three different models are compared.}
\label{compare-att}
\end{figure}

\begin{figure}
\setlength{\abovecaptionskip}{0.1cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.4cm}   %调整图片标题与下文距离
\centering
\includegraphics[width=0.45\textwidth]{f3_.pdf}
\caption{Visualization of attention weights of different aspects in the ACD task from M-CAN-2$R_o$. The a/m is short for anecdotes/miscellaneous.} 
  \label{ACD-att} 
\end{figure}

\begin{figure}
\setlength{\abovecaptionskip}{0.1cm}   %调整图片标题与图距离
\setlength{\belowcaptionskip}{-0.5cm}   %调整图片标题与下文距离
\centering
\includegraphics[width=0.45\textwidth]{loss.pdf}
\caption{The regularization loss curves of $R_s$ and $R_o$ during the training of AT-CAN-$R_o$.} 
  \label{figure:reg-loss} 
\end{figure}

\end{document}